{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpMxHlN7IGiux9jbpIE8aQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpitlabs/azure-openai-client/blob/main/simple_chatbot_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries"
      ],
      "metadata": {
        "id": "EDHwo9BttufM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "wC841Qnvtyu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the required variables, secrets etc."
      ],
      "metadata": {
        "id": "A-vr7pW5t0C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4.1-mini\"\n",
        "AZURE_ENDPOINT = \"https://arpitk-openai-003.openai.azure.com/\"\n",
        "SYSTEM_PROMPT = \"You are a helpful assistant.\"\n",
        "\n",
        "# AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
        "AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
        "print(AZURE_OPENAI_KEY)\n",
        "if not AZURE_OPENAI_KEY:\n",
        "    raise ValueError(\"Please set the AZURE_OPENAI_KEY.\")"
      ],
      "metadata": {
        "id": "D3lNpTRlt9hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize AzureOpenAI client"
      ],
      "metadata": {
        "id": "RWHoGkS8uBFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = AzureOpenAI(\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_endpoint=AZURE_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "By390RaAuCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to have a conversation with the LLM using `client`"
      ],
      "metadata": {
        "id": "l2z2BUj1uJd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def respond(message: str, chat_history):\n",
        "    \"\"\"Minimal handler: sends conversation to Azure OpenAI and returns updated history.\n",
        "\n",
        "    Expects chat_history in Gradio 'messages' format (list of {'role','content'} dicts).\n",
        "    \"\"\"\n",
        "    if not message or not message.strip():\n",
        "        return chat_history or [], \"\"\n",
        "\n",
        "    # Ensure history is a list; default to empty list\n",
        "    chat_history = chat_history or []\n",
        "\n",
        "    # Build messages for the API: system prompt + existing history + new user message\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + chat_history + [\n",
        "        {\"role\": \"user\", \"content\": message}\n",
        "    ]\n",
        "\n",
        "    # Send the messages to the LLM, get the response\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=800,\n",
        "    )\n",
        "\n",
        "    # Simple extraction with basic fallback\n",
        "    try:\n",
        "        assistant_text = resp.choices[0].message.content\n",
        "    except Exception:\n",
        "        try:\n",
        "            assistant_text = resp.choices[0].text\n",
        "        except Exception:\n",
        "            assistant_text = str(resp)\n",
        "\n",
        "    # Append to history in 'messages' format and return (plus clear textbox)\n",
        "    updated = chat_history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": assistant_text}]\n",
        "    return updated, \"\""
      ],
      "metadata": {
        "id": "hgNeM9-CuTl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initiate gradio and launch the chat interface:"
      ],
      "metadata": {
        "id": "jYndHSrYudyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset():\n",
        "    return [], \"\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Minimal Azure OpenAI + Gradio Chatbot\")\n",
        "    chatbot = gr.Chatbot(type=\"messages\", allow_tags=True)\n",
        "    txt = gr.Textbox(show_label=False, placeholder=\"Type a message and press Enter\")\n",
        "    send = gr.Button(\"Send\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    txt.submit(respond, [txt, chatbot], [chatbot, txt]) # Enter = submit\n",
        "    send.click(respond, [txt, chatbot], [chatbot, txt]) # Send = submit\n",
        "    clear.click(reset, None, [chatbot, txt])\n",
        "\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "id": "Isxf6h7Tuu0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}